{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A navigable, hierarchical keyword dictionary\n",
    "\n",
    "I wanted to build a more powerful way of handling keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: ['ae', 'ee'], 1: ['a'], 3: ['rrr']}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize(func, elements):\n",
    "    \"\"\"\n",
    "    A touch of functional programming.\n",
    "    This function classifies elements in a dictionary according\n",
    "    to the result of the function passed as parameter.\n",
    "    \"\"\"\n",
    "    dic = {}\n",
    "    for e in elements:\n",
    "        index = func(e)\n",
    "        l = dic.get(index, None)\n",
    "        if l is None:\n",
    "            dic[index] = []\n",
    "        dic[index].append(e)\n",
    "    return dic\n",
    "\n",
    "categorize(len, ['ae', 'a', 'ee', 'rrr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONST_DICT:\n",
    "    \"\"\"\n",
    "    This class is a static dictionary of constants. You could see it as a hierarchical enumeration.\n",
    "    Every level has children that either sublevels or constants of any type. A level is a Python\n",
    "    class. See further below for use.\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def contains(self, item):\n",
    "        \"\"\"\n",
    "        Returns True if the item is contained in one of the constants in the dictionary.\n",
    "        \"\"\"\n",
    "        tlv = [(k, v) for k, v in vars(self).items() if k and k[0] != '_']\n",
    "        \n",
    "        tlv = categorize(lambda x : type(x[1]), tlv)\n",
    "        \n",
    "        sub_dicts = tlv.get(type, [])\n",
    "        tlv.pop(type, None)\n",
    "        \n",
    "        for t, v in tlv.items():\n",
    "            if t in [list, tuple]:\n",
    "                for elem in v:\n",
    "                    if item in elem[1]:\n",
    "                        return True\n",
    "            else:\n",
    "                for elem in v:\n",
    "                    if item == elem[1]:\n",
    "                        return True\n",
    "                    \n",
    "        for d in sub_dicts:\n",
    "            if d[1].contains(item):\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    @classmethod\n",
    "    def get(self, item):\n",
    "        \"\"\"\n",
    "        Returns the exact path of the item if it is present in the dictionary.\n",
    "        Otherwise, return an empty string.\n",
    "        \"\"\"\n",
    "        tlv = [(k, v) for k, v in vars(self).items() if k and k[0] != '_']\n",
    "        \n",
    "        tlv = categorize(lambda x : type(x[1]), tlv)\n",
    "        \n",
    "        sub_dicts = tlv.get(type, [])\n",
    "        tlv.pop(type, None)\n",
    "        \n",
    "        for t, v in tlv.items():\n",
    "            if t in [list, tuple]:\n",
    "                for elem in v:\n",
    "                    if item in elem[1]:\n",
    "                        return self.__name__ + '.' + elem[0]\n",
    "            else:\n",
    "                for elem in v:\n",
    "                    if item == elem[1]:\n",
    "                        return self.__name__ + '.' + elem[0]\n",
    "                    \n",
    "        for d in sub_dicts:\n",
    "            ans = d[1].get(item)\n",
    "            if ans:\n",
    "                return self.__name__ + '.' + ans\n",
    "        \n",
    "        return ''\n",
    "    \n",
    "    @classmethod\n",
    "    def get_name(self, item):\n",
    "        \"\"\"\n",
    "        Returns the name of the constant where the item appears.\n",
    "        \"\"\"\n",
    "        a = self.get(item)\n",
    "        if a:\n",
    "            return a.split('.')[-1]\n",
    "        else:\n",
    "            return a\n",
    "    \n",
    "    @classmethod\n",
    "    def values(self):\n",
    "        \"\"\"\n",
    "        Returns a list of all items contained in the dictionary, regardless of\n",
    "        hierarchy.\n",
    "        \"\"\"\n",
    "        values = []\n",
    "        \n",
    "        tlv = [(k, v) for k, v in vars(self).items() if k and k[0] != '_']\n",
    "        \n",
    "        tlv = categorize(lambda x : type(x[1]), tlv)\n",
    "        \n",
    "        sub_dicts = tlv.get(type, [])\n",
    "        tlv.pop(type, None)\n",
    "        \n",
    "        for t, v in tlv.items():\n",
    "            if t in [list, tuple]:\n",
    "                for elem in v:\n",
    "                    values += (elem[1])\n",
    "            else:\n",
    "                for elem in v:\n",
    "                    values.append(elem[1])\n",
    "                    \n",
    "        for d in sub_dicts:\n",
    "            ans = d[1].values()\n",
    "            values += ans\n",
    "        \n",
    "        return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rockstar keyword dictionary\n",
    "\n",
    "Now that we have our class, we can describe the keywords of the Rockstar programming language with it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KEYWORDS(CONST_DICT):\n",
    "    class ASSIGNMENT(CONST_DICT):\n",
    "        PUT = 'Put'\n",
    "        INTO = 'into'\n",
    "        PREFIX = 'Put'\n",
    "        SUFFIX = 'into'\n",
    "\n",
    "    SAY = ['Shout', 'Say', 'Whisper', 'Scream']\n",
    "    \n",
    "    STUTTER = (\"Spit\", 'Stutter')\n",
    "\n",
    "    class OPERATOR(CONST_DICT):\n",
    "        class CONDITIONAL(CONST_DICT):\n",
    "            NEQ = ['is not', \n",
    "                   'aint', \n",
    "                   'werent', \n",
    "                   'wasnt']\n",
    "            \n",
    "            GT = ['higher than',\n",
    "                  'greater than',\n",
    "                  'more than',\n",
    "                  'stronger than',\n",
    "                  'bigger than']\n",
    "            \n",
    "            LT = ['lower than',\n",
    "                 'less than',\n",
    "                 'weaker than',\n",
    "                 'smaller than']\n",
    "            \n",
    "            GE = ['as high as',\n",
    "                  'as big as',\n",
    "                  'as strong as',\n",
    "                  'as great as',\n",
    "                  'as beautiful as']\n",
    "            \n",
    "            LE = ['as low as',\n",
    "                  'as small as',\n",
    "                  'as weak as',\n",
    "                  'as bad as',\n",
    "                  'as little as',\n",
    "                  'as ugly as']\n",
    "            \n",
    "        class ARITHMETIC(CONST_DICT):\n",
    "            ADD = ['plus', 'with']\n",
    "            SUB = ['minus', 'without']\n",
    "            DIV = 'over'\n",
    "            MUL = ['times', 'of']\n",
    "        \n",
    "        class INCREMENT(CONST_DICT):\n",
    "            BUILD = 'Build'\n",
    "            UP = 'up'\n",
    "            PREFIX = 'Build'\n",
    "            SUFFIX = 'up'\n",
    "            \n",
    "        class DECREMENT(CONST_DICT):\n",
    "            PREFIX = 'Knock'\n",
    "            SUFFIX = 'down'\n",
    "            \n",
    "        class FLOW(CONST_DICT):\n",
    "            WHILE = 'While'\n",
    "            IF = 'If'\n",
    "            UNTIL = 'Until'\n",
    "            \n",
    "    class POETIC(CONST_DICT):\n",
    "        class LITERAL(CONST_DICT):\n",
    "            class BOOLEAN(CONST_DICT):\n",
    "                TRUE = (\"true\", \"right\", \"yes\", \"ok\")\n",
    "                FALSE = (\"false\", \"wrong\", \"no\", \"lies\")\n",
    "            NULL = (\"null\", \"nobody\", \"nowhere\", \"empty\", \"gone\")\n",
    "            \n",
    "        ASSIGNMENT = ['is', 'was', 'were']\n",
    "          \n",
    "    PRONOUN = (\"it\", \"he\", \"she\", \"him\", \"her\", \"they\", \"them\")\n",
    "            \n",
    "    class FUNCTION(CONST_DICT):\n",
    "        DECLARATION = 'takes'\n",
    "        CALL = 'taking'\n",
    "        RETURN = 'Give back'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYWORDS.contains('is'), KEYWORDS.contains('over'), KEYWORDS.contains(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('KEYWORDS.OPERATOR.CONDITIONAL.NEQ', 'KEYWORDS.OPERATOR.ARITHMETIC.DIV', '')"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYWORDS.get('aint'), KEYWORDS.get('over'), KEYWORDS.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KEYWORDS.SAY'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYWORDS.get('Shout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shout',\n",
       " 'Say',\n",
       " 'Whisper',\n",
       " 'Scream',\n",
       " 'Spit',\n",
       " 'Stutter',\n",
       " 'it',\n",
       " 'he',\n",
       " 'she',\n",
       " 'him',\n",
       " 'her',\n",
       " 'they',\n",
       " 'them',\n",
       " 'Put',\n",
       " 'into',\n",
       " 'Put',\n",
       " 'into',\n",
       " 'is not',\n",
       " 'aint',\n",
       " 'werent',\n",
       " 'wasnt',\n",
       " 'higher than',\n",
       " 'greater than',\n",
       " 'more than',\n",
       " 'stronger than',\n",
       " 'bigger than',\n",
       " 'lower than',\n",
       " 'less than',\n",
       " 'weaker than',\n",
       " 'smaller than',\n",
       " 'as high as',\n",
       " 'as big as',\n",
       " 'as strong as',\n",
       " 'as great as',\n",
       " 'as beautiful as',\n",
       " 'as low as',\n",
       " 'as small as',\n",
       " 'as weak as',\n",
       " 'as bad as',\n",
       " 'as little as',\n",
       " 'as ugly as',\n",
       " 'plus',\n",
       " 'with',\n",
       " 'minus',\n",
       " 'without',\n",
       " 'times',\n",
       " 'of',\n",
       " 'over',\n",
       " 'Build',\n",
       " 'up',\n",
       " 'Build',\n",
       " 'up',\n",
       " 'Knock',\n",
       " 'down',\n",
       " 'While',\n",
       " 'If',\n",
       " 'Until',\n",
       " 'is',\n",
       " 'was',\n",
       " 'were',\n",
       " 'null',\n",
       " 'nobody',\n",
       " 'nowhere',\n",
       " 'empty',\n",
       " 'gone',\n",
       " 'true',\n",
       " 'right',\n",
       " 'yes',\n",
       " 'ok',\n",
       " 'false',\n",
       " 'wrong',\n",
       " 'no',\n",
       " 'lies',\n",
       " 'takes',\n",
       " 'taking',\n",
       " 'Give back']"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYWORDS.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordDictionary:\n",
    "    \"\"\"\n",
    "    If you are lazy like me, you may want to be able to overload operators to \n",
    "    write more expressive (ie less) code. We can't do that on raw classes, so \n",
    "    we need a instantiated class that serves as an interface between the static \n",
    "    class and our program. Python is magic.\n",
    "    \"\"\"\n",
    "    def __init__(self, const_dict):\n",
    "        \n",
    "        self.cdict = const_dict\n",
    "        \n",
    "        tlv = [(k, v) for k, v in vars(self.cdict).items() if k and k[0] != '_']\n",
    "        \n",
    "        tlv = categorize(lambda x : type(x[1]), tlv)\n",
    "        \n",
    "        sub_dicts = tlv.get(type, [])\n",
    "        tlv.pop(type, None)\n",
    "        \n",
    "        for t, v in tlv.items():\n",
    "            for elem in v:\n",
    "                setattr(self, *elem)\n",
    "        \n",
    "        for d in sub_dicts:\n",
    "            setattr(self, d[0], self.__class__(d[1]))\n",
    "            \n",
    "    def __contains__(self, item):\n",
    "        return self.cdict.contains(item)\n",
    "    def __getitem__(self, item):\n",
    "        return self.cdict.get(item)\n",
    "    def __call__(self, item):\n",
    "        return self.cdict.get_name(item)\n",
    "    def get(self, item):\n",
    "        return self[item]\n",
    "    def name(self, item):\n",
    "        return self.cdict.get_name(item)\n",
    "    def values(self, item):\n",
    "        return self.cdict.values()\n",
    "    def __str__(self):\n",
    "        return str(vars(self))\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd = KeywordDictionary(KEYWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'KEYWORDS.OPERATOR.CONDITIONAL.GE', 'GE', 'GE', '')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can write\n",
    "'true' in kd.POETIC, kd['as high as'], kd('as high as'), kd.name('as high as'), kd('non-existing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'KEYWORDS.OPERATOR.CONDITIONAL.GE', 'GE')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of\n",
    "KEYWORDS.POETIC.contains('true'), KEYWORDS.get('as high as'), KEYWORDS.get_name('as high as')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store our operations in the same way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "class OPERATIONS(CONST_DICT):\n",
    "    class ARITHMETIC(CONST_DICT):\n",
    "        ADD = operator.add\n",
    "        SUB = operator.sub\n",
    "        DIV = operator.truediv\n",
    "        MUL = operator.mul\n",
    "    class CONDITIONAL(CONST_DICT):\n",
    "        EQ = operator.eq\n",
    "        NE = operator.ne\n",
    "        LT = operator.lt\n",
    "        LE = operator.le\n",
    "        GT = operator.gt\n",
    "        GE = operator.ge\n",
    "        OR = operator.or_\n",
    "        AND = operator.and_\n",
    "        TRUTH = operator.truth\n",
    "        NOT = operator.__not__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple tokenization with our Rockstar keyword dictionary\n",
    "\n",
    "Now that our dictionary has been defined, we can try to use the tokenization function from the expression parser. This function takes a list of entities that needs to be tokenized first, then tokenizes the rest of the text in string and number literals. Everything else is tokenized on a word basis. \n",
    "\n",
    "I am taking this code from `test-bool.rock` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"Put 1 into my heart\n",
    "Put 2 into my arm\n",
    "Put 3 into my head\n",
    "Put 0 into my test\n",
    "Put 6 into the allfather\n",
    "\n",
    "If my head is not my heart\n",
    "Say \"is not: Okay\"\n",
    "Put my test plus 1 into my test\n",
    "\n",
    "If my head is my head\n",
    "Say \"is: Okay\"\n",
    "Put my test plus 1 into my test\n",
    "\n",
    "If my arm aint my head\n",
    "Say \"aint: Okay\"\n",
    "Put my test plus 1 into my test\n",
    "\n",
    "If my head is more than my heart\n",
    "Say \"is X than: Okay\"\n",
    "Put my test plus 1 into my test\n",
    "\n",
    "If my arm is less than 5\n",
    "Say \"is X than numeric literal: Okay\"\n",
    "Put my test plus 1 into my test\n",
    "\n",
    "If my arm is as high as my heart\n",
    "Say \"is as X as: Okay\"\n",
    "Put my test plus 1 into my test\n",
    "\n",
    "If my test is the allfather\n",
    "Say \"All tests passed\"\n",
    "\n",
    "If my test is not the allfather\n",
    "Spit my test over the allfather\n",
    "Shout \"tests passed\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def rgxer(sss):\n",
    "    result = ''\n",
    "    for c in sss:\n",
    "        if c in '.<>*[]{}+':\n",
    "            result += '[' + c + ']'\n",
    "        else:\n",
    "            result += c\n",
    "    return result\n",
    "\n",
    "def match(regex, token):\n",
    "    return bool(re.match('^{}$'.format(regex), token))\n",
    "\n",
    "def find_all(ss, s):\n",
    "    \"\"\"\n",
    "    Return all occurences of a substring found in a string.\n",
    "    Ouput is (<start>, <end>) of occurence\n",
    "    \"\"\"\n",
    "    pos = []\n",
    "    p = 0\n",
    "    offset = 0\n",
    "    while p + 1 and ss:\n",
    "        p = ss.find(s)\n",
    "        if p + 1:\n",
    "            pos.append((offset + p, offset + p + len(s)))\n",
    "            ss = ss[p+1:]\n",
    "            offset += p + 1\n",
    "    return pos\n",
    "\n",
    "def tokenize(expr, entities=[]):\n",
    "    \"\"\"\n",
    "    The big, fluffy tokenize function.\n",
    "    This function will tokenize as following :\n",
    "    You can give it a list of entities that will be prioritized over any token, \n",
    "    except if they are in a \"string literal\".\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    item = ''\n",
    "    entities = sorted(entities, key=len)\n",
    "    entity_occs = [(entity, find_all(expr, entity)) for entity in entities]\n",
    "    entity_occs = [e for e in entity_occs if e[1]]\n",
    "    found_entities = {occ[0]: (occ[1], occs[0]) for occs in entity_occs for occ in occs[1]}\n",
    "    \n",
    "    ignoring = 0\n",
    "    in_quotes = ''\n",
    "    for i, e in enumerate(expr):\n",
    "        if ignoring:\n",
    "            ignoring -= 1\n",
    "            continue\n",
    "            \n",
    "        if not in_quotes and e in ['\"', \"'\"]:\n",
    "            in_quotes = e\n",
    "            items.append(item) if item else None\n",
    "            item = e        \n",
    "            \n",
    "        elif in_quotes:\n",
    "            if e == in_quotes:\n",
    "                in_quotes = ''\n",
    "                item += e\n",
    "                items.append(item) if item else None\n",
    "                item = ''\n",
    "            else:\n",
    "                item += e\n",
    "        \n",
    "        elif i in found_entities and not match('[a-zA-Z][a-zA-Z0-9]*', found_entities[i][1]):\n",
    "\n",
    "            # if found entity is all letters and item is not empty, do nothing\n",
    "            # else\n",
    "            ignoring = found_entities[i][0] - i - 1\n",
    "            items.append(item) if item else None\n",
    "            item = ''\n",
    "            items.append(found_entities[i][1])\n",
    "        \n",
    "        elif match('[\\w.]', e):\n",
    "            item += e\n",
    "        elif e == ' ':\n",
    "            items.append(item) if item else None\n",
    "            item = ''\n",
    "        else:\n",
    "            items.append(item) if item else None\n",
    "            item = ''\n",
    "            items.append(e)\n",
    "        \n",
    "    if item:\n",
    "        items.append(item)    \n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put 1 into my heart\n",
      "['Put', '1', 'into', 'my', 'heart']\n",
      "PUT 1 INTO my heart\n",
      "\n",
      "Put 2 into my arm\n",
      "['Put', '2', 'into', 'my', 'arm']\n",
      "PUT 2 INTO my arm\n",
      "\n",
      "Put 3 into my head\n",
      "['Put', '3', 'into', 'my', 'head']\n",
      "PUT 3 INTO my head\n",
      "\n",
      "Put 0 into my test\n",
      "['Put', '0', 'into', 'my', 'test']\n",
      "PUT 0 INTO my test\n",
      "\n",
      "Put 6 into the allfather\n",
      "['Put', '6', 'into', 'the', 'allfather']\n",
      "PUT 6 INTO the allfather\n",
      "\n",
      "If my head is not my heart\n",
      "['If', 'my', 'head', 'is not', 'my', 'heart']\n",
      "IF my head NEQ my heart\n",
      "\n",
      "Say \"is not: Okay\"\n",
      "['Say', '\"is not: Okay\"']\n",
      "SAY \"is not: Okay\"\n",
      "\n",
      "Put my test plus 1 into my test\n",
      "['Put', 'my', 'test', 'plus', '1', 'into', 'my', 'test']\n",
      "PUT my test ADD 1 INTO my test\n",
      "\n",
      "If my head is my head\n",
      "['If', 'my', 'head', 'is', 'my', 'head']\n",
      "IF my head ASSIGNMENT my head\n",
      "\n",
      "Say \"is: Okay\"\n",
      "['Say', '\"is: Okay\"']\n",
      "SAY \"is: Okay\"\n",
      "\n",
      "Put my test plus 1 into my test\n",
      "['Put', 'my', 'test', 'plus', '1', 'into', 'my', 'test']\n",
      "PUT my test ADD 1 INTO my test\n",
      "\n",
      "If my arm aint my head\n",
      "['If', 'my', 'arm', 'aint', 'my', 'head']\n",
      "IF my arm NEQ my head\n",
      "\n",
      "Say \"aint: Okay\"\n",
      "['Say', '\"aint: Okay\"']\n",
      "SAY \"aint: Okay\"\n",
      "\n",
      "Put my test plus 1 into my test\n",
      "['Put', 'my', 'test', 'plus', '1', 'into', 'my', 'test']\n",
      "PUT my test ADD 1 INTO my test\n",
      "\n",
      "If my head is more than my heart\n",
      "['If', 'my', 'head', 'is', 'more than', 'my', 'heart']\n",
      "IF my head ASSIGNMENT GT my heart\n",
      "\n",
      "Say \"is X than: Okay\"\n",
      "['Say', '\"is X than: Okay\"']\n",
      "SAY \"is X than: Okay\"\n",
      "\n",
      "Put my test plus 1 into my test\n",
      "['Put', 'my', 'test', 'plus', '1', 'into', 'my', 'test']\n",
      "PUT my test ADD 1 INTO my test\n",
      "\n",
      "If my arm is less than 5\n",
      "['If', 'my', 'arm', 'is', 'less than', '5']\n",
      "IF my arm ASSIGNMENT LT 5\n",
      "\n",
      "Say \"is X than numeric literal: Okay\"\n",
      "['Say', '\"is X than numeric literal: Okay\"']\n",
      "SAY \"is X than numeric literal: Okay\"\n",
      "\n",
      "Put my test plus 1 into my test\n",
      "['Put', 'my', 'test', 'plus', '1', 'into', 'my', 'test']\n",
      "PUT my test ADD 1 INTO my test\n",
      "\n",
      "If my arm is as high as my heart\n",
      "['If', 'my', 'arm', 'is', 'as high as', 'my', 'heart']\n",
      "IF my arm ASSIGNMENT GE my heart\n",
      "\n",
      "Say \"is as X as: Okay\"\n",
      "['Say', '\"is as X as: Okay\"']\n",
      "SAY \"is as X as: Okay\"\n",
      "\n",
      "Put my test plus 1 into my test\n",
      "['Put', 'my', 'test', 'plus', '1', 'into', 'my', 'test']\n",
      "PUT my test ADD 1 INTO my test\n",
      "\n",
      "If my test is the allfather\n",
      "['If', 'my', 'test', 'is', 'the', 'allfather']\n",
      "IF my test ASSIGNMENT the allfather\n",
      "\n",
      "Say \"All tests passed\"\n",
      "['Say', '\"All tests passed\"']\n",
      "SAY \"All tests passed\"\n",
      "\n",
      "If my test is not the allfather\n",
      "['If', 'my', 'test', 'is not', 'the', 'allfather']\n",
      "IF my test NEQ the allfather\n",
      "\n",
      "Spit my test over the allfather\n",
      "['Spit', 'my', 'test', 'over', 'the', 'allfather']\n",
      "STUTTER my test DIV the allfather\n",
      "\n",
      "Shout \"tests passed\"\n",
      "['Shout', '\"tests passed\"']\n",
      "SAY \"tests passed\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in code.split('\\n'):\n",
    "    line = line.strip()\n",
    "    if not line or line and line[0] == '(':\n",
    "        continue\n",
    "    print(line)\n",
    "    print(tokenize(line, KEYWORDS.values()))\n",
    "    print(*map(lambda x : KEYWORDS.get_name(x) if x in KEYWORDS.values() else x, tokenize(line, KEYWORDS.values())))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the tokenization correctly captures keywords separately. But as some of them can appear as inert tokens unless they follow a specific pattern (for instance, `times` is a keyword, but can also appear as a regular word), we can't just do a search-and-replace as done above after the tokenization function. We need to disambiguate according to their position and neighborhood. That's what the current tokenization function does.\n",
    "\n",
    "There may also be a need for disambiguation if by any chance, any of our multi-word keywords is allowed to appear as regular tokens, since this tokenization function automatically merges them when spotted.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
